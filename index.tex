\documentclass[12pt]{report}

%%
% to enumerate subsubsection
%%
\addtocounter{tocdepth}{3}
\setcounter{secnumdepth}{3}
% \usepackage{tgtermes}
\usepackage[a4paper, margin=1in]{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{graphicx} 
\usepackage{tikz}
\usepackage{amsmath, amssymb}
% \usepackage{indentfirst}
% \usepackage{cite}
\usepackage{natbib}
\usepackage[nameinlink,noabbrev]{cleveref}
\usepackage[capposition=top]{floatrow}
\usepackage{float}
\usepackage{caption}
\usepackage{xfrac}
\usepackage{braket}
\usepackage[toc,page]{appendix}
\usepackage{tabularx}
% \usepackage{hyperref}
% \usepackage{physics}

%%
% to enumerate subsubsection
%%
\addtocounter{tocdepth}{3}
\setcounter{secnumdepth}{3}

% Snippet
\newcommand{\BSM}{Black--Scholes--Merton }
\newcommand{\lnorm}{log-normally }
\newcommand{\bmotion}{Brownian Motion }
\newcommand{\stvar}{stochastic variable }
\newcommand{\wienpro}{Wiener process }
\newcommand{\markpro}{Markov process }

% 
% Bunch of new commands
% 
% brownian motion
\newcommand{\dBm}{dW\left(t\right)}
\newcommand{\dpoiss}{dq\left(t\right)}
\newcommand{\DBm}{\delta{W\left(t\right)}}
\newcommand{\Bm}{W\left(t\right)}
\newcommand{\Bmsub}[1]{W_{#1}\left(t\right)}
\newcommand{\Dt}{\Delta t} 
\newcommand{\Bmdist}{\DBm \sim N \left( 0, \Dt \right)}
\newcommand{\ft}{f\left(t, \Bm \right)}
\newcommand{\E}{\mathop{\mathbb{E}}}
\newcommand{\ct}{c\left(t, x\right)}
\newcommand{\dcx}{\frac{\delta\ct}{\delta x}}
\newcommand{\dciix}{\frac{\delta^2\ct}{\delta x^2}}
\newcommand{\dct}{\frac{\delta\ct}{\delta t}}
\newcommand{\N}[1]{N\left(#1\right)}
\newcommand{\dsub}[1]{d_{#1}\left(\Dt, x\right)}
\newcommand{\call}[2]{c\left( #1, #2\right)}
% % about stock
\newcommand{\St}{S\left(t\right)}
\newcommand{\Vt}{V\left(t\right)}
\newcommand{\Si}{S\left(0\right)}
\newcommand{\dSt}{dS\left(t\right)}
\newcommand{\DSt}{\Delta S\left(t\right)}
\newcommand{\dSr}{\frac{\dSt}{\St}}
\newcommand{\DSr}{\frac{\DSt}{\St}}
\newcommand{\Scontinuous}{\St = \Si e^{\sigma\Bm + \left(\alpha - \frac{1}{2 \sigma^2}\right)t}}
\newcommand{\Itobmdiff}{d\ft = \left[\frac{\partial \ft }{\partial t} + \frac{1}{2} \frac{\partial ^2\ft }{\partial x^2}\right]dt + \frac{\partial \ft}{\partial x} \dBm}
\newcommand{\Scontinousdiff}{d\St &= \alpha \St dt + \sigma \St \dBm}
\newcommand{\Scontinuousrate}{\dSr &= \alpha dt + \sigma \dBm}
 \newcommand{\Sdiscretediff}{d\St &= \alpha \St \Dt + \sigma \St \dBm}
\newcommand{\Sshort}{\Si e^{X}}
\newcommand{\CCRdist}{X \sim N\left(\left(\alpha - \frac{1}{2}\sigma^2\right)t, \sigma^2 t\right)}
\newcommand{\Sdiscreterate}{\DSr &= \alpha \Delta t + \sigma \DBm}
\newcommand{\Sdiscreterateexp}{\E \DSr = \alpha \Dt}
\newcommand{\Sdiscreteratevar}{var \DSr = \sigma ^2 \Dt}
\newcommand{\Sdiscreteratedist}{\DSr \sim N\left(\alpha\Dt, \sigma\Dt\right)}
\newcommand{\Sexp}{\E\St = \Si e^{\alpha t}}
\newcommand{\Svar}{var\St = \Si^2 e^{2\alpha t}\left(e^{\sigma^2 t} - 1\right)}
\newcommand{\Sshortt}{\St = \Si e^{X t}}
\newcommand{\CCRt}{X = \frac{1}{t} \ln{\frac{\St}{\Si}}}
\newcommand{\CCRtdist}{X \sim N\left(\alpha - \frac{\sigma^2}{2}, \frac{\sigma^2}{t}\right)}
\newcommand{\BSMpde}{\dct + r x \dcx + \frac{1}{2} \sigma^2 x^2 \dciix = r\ct}
\newcommand{\BSMeq}[1]{r\call{t}{#1} = \frac{\partial \call{t}{#1}}{\partial t} + r #1 \frac{\partial \call{t}{#1}}{\partial #1} + \frac{1}{2} \sigma ^2 #1 ^2 \frac{\partial ^2 \call{t}{#1}}{\partial #1 ^2}}
\newcommand{\BSMGreeks}[1]{r\call{t}{#1} = \Theta + r #1 \Delta + \frac{1}{2} \sigma ^2 #1 ^2 \Gamma}
\newcommand{\BSMsol}{\ct &= x\N{\dsub{+}} - K e^{-r\Dt} \N{\dsub{-}}}
\newcommand{\dpm}{\dsub{\pm} &= \frac{1}{\sigma\sqrt{\Dt}} \left[\log\frac{x}{K} + \left(r \pm \frac{\sigma^2}{2}\Dt\right)\right]}

% CIR Stock price Stochastic process
\newcommand{\HSVstock}{
  d\St &= \alpha \St dt + \sqrt{\Vt} \St d \Bmsub{S}
}

% CIR Stock price Stochastic process
\newcommand{\HSVstockriskless}{
  d\St &= r \St dt + \sqrt{\Vt} \St d \Bmsub{S}
}

% CIR volatility
\newcommand{\HSVvol}{
  d\Vt &= \kappa\left(\theta - \Vt \right) dt + \sigma \sqrt{\Vt} d \Bmsub{V}
}


% CIR volatility
\newcommand{\HSVvolriskless}{
  d\Vt &= \kappa^{*} \left(\theta^{*} - \Vt \right) dt + \sigma \sqrt{\Vt} d \Bmsub{V}
}

\newcommand{\dportfolio}{dX\left(t\right) &= \Delta\left(t\right) d\St + r \left(X\left(t\right) - \Delta\left(t\right) \St \right) dt}

\usepackage{Sweave}
\begin{document}
\input{index-concordance}
\tableofcontents{}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  CHAPTER: Introduction
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Introduction}
\label{cha:Introduction}
\addcontentsline{toc}{chapter}{Introduction}

Talk about what is done to price a vanilla option throuhout the BSM method.
How does the BSM model is fair under its assumption. What about if we are going beyond ?
How perfomant is it ? 
What about other model such as \ldots ?

Using R. \cite{R}
% \SweaveInput{upstream}
% \SweaveInput{underlying}
% \SweaveInput{BSM}
% \SweaveInput{models}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  CHAPTER:Methodology
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Methodology}
\label{cha:Methodology}


\section{Overview}
\label{sec:methodology:overview}

The objective of this master thesis is to measure the performances of the Black-Scholes-Merton pricing method when the assumption of normality for the log-return's distribution is not met.
In order to measure such performances, the method I will follow is to apply the delta-hedging rule on options for which the underlying distribution is not log-normal.
Instead of fully use market data to make those experiments, I will rather construct some theoretical time series based on the theories developed by \citet{merton76} and \citet{heston1993} in order to repectively obtains path with jumps and others with stochastic volatility.
To do so, I will construct algorithms to implement those models. 

Even though I won't construct my hedge directly on market data, I will furthermore use them to calibrate the parameters I will pass to the algorithms I developed.
I chose to use the available market data on Apple stock and Apple call option for the calibration process.

Once all my parameters will be calibrated, I will simulate time series representing as many paths that could be followed by a share of stock. The simulation of that asset path will be driven either by a Merton mixed jump-diffusion process or by a Heston stochastic volatility process.

Thereafter I will apply multiple scenarios of delta-hedging on each path of all sampled processes for different options with different maturities and strike.
Ultimately though, I will compare the result of each delta hedging scenario.






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: calibration
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Calibration}
\label{sec:methodology:calibration}

Whenever one deals with functions aimed to reproduce some real life experiments, the calibration process is crutial because it gives to the functions the capacity to behave within the right borders along with the right values.

For what matter in the analysis I want to perform is to find consistent values for the parameters to pass to the functions aimed to either determine option prices or to simulate stock market data.
By consistent, I mean that they should make the functions' output connected with what is observer in the real world.

The process of calibration concerns two distinctive groups of parameters. Those intended to compute the european call price and those used to simulate the hypothetical stock market movements.
Consequently, the method to calibrate both kinds of arguments differs, mainly because option prices calculation must be performed under risk-neutral environment.

To do so, I am going to use the available option price data to calibrate the arguments aimed to compute the price of that latter.
Whilst I am going to use the stock's historical data to get the right values for the time serie's functions.

\Cref{sub:methodology:calibration:option} explains how I will operate for the options' parameters, whereas \cref{sub:methodology:calibration:asset} shows the procedure I will follow for the stock simulation's arguments.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SUBSECTION: Option prices' calibration
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Option prices based calibration}
\label{sub:methodology:calibration:option}

Following \citet{heston1993} and \citet{criso2015}, provided that the characteristic functions of the model of Merton mixed-jump diffusion or the one of Heston stochastic volatility is known, the european call option price of such underlying processes can be computed using \cref{eq:other:call:heston}.
although known, these characteristics functions needs somes parameters to work and those parameters need values to best fit with what is observed in reality.
That is why both functions need to be benchmarked with a referential value  before being used.
For what matter in this current master thesis, the referential value for option calibration is the Apple option martket prices.

To do so, I will apply the same method followed by \citet{criso2015}, namely, I will iterativaly minimize the difference between the Apple option market prices and those generated by the function that compute the option prices based on the characteristic functions.

The option market prices were downloaded using the package \textit{quantmod}, developed by \citet{quantmod} which uses Yahoo! finance as provider. The dataset so downloaded is available in appendix \ref{cha:appendix:market}.
\cref{t:methodology:maturity,t:methodology:strike} respectively show the maturities and the strike that will be considered during the analysis.

\begin{table}[ht]
\centering
\begin{tabular}{lllllll}
  63 & 91 & 126 & 154 & 182 & 245 & 399 \\
\end{tabular}
\caption{Taking into account maturities during calibration stage} 
\label{t:methodology:maturity}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{llllllllll}
  130 & 140 & 150 & 160 & 170 & 180 & 190 & 200 & 210 & 220 \\  
\end{tabular}
\caption{Taking into account strikes during calibration stage} 
\label{t:methodology:strike}
\end{table}

The next step is the creation of algorithm aimed to compute the option prices. To do so I have created two R functions to compute the characteristic functions of the Merton jump-diffusion and Heston stochastic characteristic process. For more information see REF + REF on appendix \cref{cha:r}.

Once both market data gathered and pricing algorithm created, the next step is the set up of the cost function to be minimized, by using the least-square non linear regession model.
As previously mentioned, the optimal result is the one that minimize the squared difference between market and genereated data, as exposed by \cref{eq:methodology:cost}

\begin{align}
 &\left(C_{K,T}^{mkt} - C_{K,T}^{h|m}(arguments)\right)^2
 \label{eq:methodology:cost}\\
 \forall &K \in \{130, 140, 150, 160, 170, 180, 190, 200, 210, 220\}, \notag\\
 &T \in \left \{63, 91, 126, 154, 182, 245, 399\right \}\notag 
\end{align}
Where the subscript $K$ and $T$ respectively stand for strike price and maturity date. While the superscript $mkt$ denotes the "market price" and $h|m$ refers to either Heston or Merton process based prices.

Consequently, \cref{eq:methodology:cost} will be the one to minimize using the least-square non linear regression model, for all strikes and maturities.
The output of this process will evetually be the calibrated arguments that maximize the performance of the model across what is observed in the reality.

One dificulty to deal with is that the least-square non linear approach may return several best fit arguments due to the existence of multiple local minima in the cost function, depending on the parater given to the theoretical model.
Therefore, in order to choose among all the outputs, I will select the one with which I get the most returns within the bid-ask spread of option market data.

\begin{align}
 \left | C_{K,T}^{mkt} - C_{K,T}^{h|m}(arguments) \right | \leq C_{ask}^{mkt} - C_{bid}^{mkt}
 \label{eq:methodology:cost}
\end{align}

Even though the cost fustion to be optimized is the same for both Heston and Merton pricing option procedure, the arguments to calibrate are different. \cref{sub:methodology:calibration:merton,sub:methodology:calibration:heston} respectively show the procedure for Merton and Heston.

[TODO: NOM DES FONCTIONS + OU LES TROUVER]
 
% SUBSECTION: Asset prices based calibration

\subsection{Asset prices based calibration}
\label{sub:methodology:calibration:asset}

In order to calibrate the parameters to pass to the Merton jump-difusion and Heston stochastic volatility model, to generate all the dummy times series that will serve for the analysis of the delta hedging, I will use the historical market data on the Apple stock as template.

To perform such an upstream analysis, I will use an approximation method to estimate the arguments with which the distribution of the log-returns generated by both MJD and HSV models better fit the density curve of the historical log-return.
To get the historical data, I will once more use the package \textit{quantmod}, developed by \citet{quantmod} which uses Yahoo! finance as provider. The dataset so downloaded is available in appendix \ref{cha:appendix:apple} and concern the daily stock price from 18th May 2017 to 18th May 2018.
\cref{p:methodology:density:aapl} show the density curve generated by the log-return of the historical data.

[PLOT]

% Practically, to perform the calibration, I will use an approximation algorithm developed by \cite{MASS} which is directly available in R through the function \textit{fitdistr} from the R package \textit{MASS}. 
% To do the job, that algorithm needs (i) a density function to be fitted along with (ii) a sample of random data as a template.

The procedures to calibrate the arguments for Merton jump-diffusion process and Heston stochastic volatility are respectively explained at \cref{sub:methodology:calibration:merton,sub:methodology:calibration:heston}.


% SUBSECTION: Merton's model calibration

\subsection{Merton's model calibration}
\label{sub:methodology:calibration:merton}


% SUBSECTION: Heston's model calibration

\subsection{Heston's model calibration}
\label{sub:methodology:calibration:heston}

\subsubsection*{Calibration of parameters for option pricing}

In order to use \cref{eq:other:call:heston} to compute the price of european call options on an underlying with increments driven by HSV, the parameters $(V(0), \kappa, \theta, \sigma, \rho)$ must be calibrated with respect to the available option market data.
Consequently, the so estimated parameters would be in line with the risk-neutral measre, or specifically $\kappa$ and $\theta$, which are the only ones adapted to make \cref{eq:other:hsvvol:riskless} risk-neutral.

To do so, I am goind to use the aformentioned least-square non linear regression model together with data, described in appendix \ref{cha:appendix:market}, as template.
In this instance, the theoretical model to calibrate is given by \crefrange{eq:other:call:heston}{eq:other:call:heston:pi2} along with \cref{eq:other:heston:psi}.

Moreover, to stay in a range of acceptable values, the parameters of the HSV model should lie between some defined boundaries and constraints. 

De facto, the mean-reversion speed ($\kappa$), the long-run variance ($\theta$) and the volatility of the volatility ($\sigma$) need to take values that together respect the feller condition (see \cref{sub:other:heston:feller}). Additionally, $\sigma$ ranges between 0 and 1 and, following \citet{cristo2015} $\kappa$ should be positive to avoid mean aversion.

Although the correlation coeficient $\rho$ may take any value from $[-1, 1]$, typically the correlation between a stock price increments and its intrinsic volatility is negative. Consequently, I choose to set the borders of $\rho$ as being $]0, -1[$.

According to those boundary conditions, the \textit{nls} function returns \cref{t:methodology:call:heston:estimate1} as the whole sets of parameters that better fit the model \cref{eq:other:call:heston} to reality.

\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
v0 & theta & sigma & rho & kappa \\ 
  \hline
0.03835 & 0.05144 & 0.30882 & -0.40228 & 1.99821 \\ 
  0.03851 & 0.05142 & 0.29539 & -0.49338 & 1.99931 \\ 
  0.03850 & 0.05241 & 0.30601 & -0.59979 & 1.99843 \\ 
  0.03774 & 0.04832 & 0.30687 & -0.40213 & 3.00036 \\ 
  0.03827 & 0.04954 & 0.40690 & -0.40189 & 3.00011 \\ 
  0.03883 & 0.04798 & 0.30747 & -0.50211 & 3.00015 \\ 
  0.03910 & 0.04948 & 0.40736 & -0.50193 & 3.00005 \\ 
  0.03695 & 0.04703 & 0.30697 & -0.40288 & 4.00092 \\ 
  0.04449 & 0.04443 & 0.40682 & -0.40289 & 4.00079 \\ 
  0.03798 & 0.04872 & 0.50379 & -0.39878 & 4.00106 \\ 
  0.04091 & 0.04651 & 0.40705 & -0.50227 & 4.00097 \\ 
  0.03740 & 0.04754 & 0.30583 & -0.60126 & 4.00096 \\ 
  0.03890 & 0.04792 & 0.40565 & -0.60086 & 4.00091 \\ 
  0.03661 & 0.04604 & 0.30659 & -0.40295 & 5.00152 \\ 
  0.04034 & 0.04547 & 0.40591 & -0.40298 & 5.00153 \\ 
  0.04111 & 0.04558 & 0.50652 & -0.40298 & 5.00144 \\ 
  0.04034 & 0.04720 & 0.60647 & -0.40250 & 5.00138 \\ 
  0.03921 & 0.04709 & 0.50753 & -0.50170 & 5.00152 \\ 
  0.03789 & 0.04656 & 0.30488 & -0.80072 & 5.00164 \\ 
   \hline
\end{tabular}
\caption{Best estimates for HSV call option model} 
\label{t:methodology:call:heston:estimate1}
\end{table}

The set \ref{eq:methodology:arg:heston:riskneutral} is the one making respond the model the best with what is observed in reality.
Indeed when passing that set to the R function \textit{call\_heston()}, for all strikes of \cref{t:methodology:strike} and maturities of \cref{t:methodology:maturity}, more than $70\%$ of the so generated prices are within the bid-ask spread of the Apple option historical data.

\begin{align}
  \left \{
  \begin{array}{lcl}
    V(0) &= &0.03798218, \\
    \theta &= &0.04871543, \\
    \sigma &= &0.50378803, \\
    \rho &= &-0.39877827, \\
    \kappa &= &4.00105546 
  \end{array}
  \right \}  
  \label{eq:methodology:arg:heston:riskneutral}
\end{align}

FIGURE X confronts the blue colored volatility smiles computed from market data, with those in red, calculated from the theoretical model generated option price.

[FIRURE]


Consequently, the set \ref{eq:methodology:arg:heston:riskneutral} is the one I will use together with the \textit{heston\_call()} function whenever I have to compute option price using the HSV model.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Calibration of parameters for time series}

The  set \ref{eq:methodology:arg:heston:riskneutral} is calibrated under the risk-neutral world and cannot therefore be used as is to simulate the dummy time series that will be used in the analysis aimed to measure the delta hedging performance.
In addition to those parameters, the drift rate has to be estimated as well. It was not present in the set  \ref{eq:methodology:arg:heston:riskneutral} because it is not taken into account in the computation of the options prices.

FIGURE x shows the empirical density curves illustrating the distributions of the log-returns computed either from historical Apple stock data for the blue curve or from dummy time series generated by the function \textit{HSV\_ts()} fed with the risk-neutral parameters, for the red one.


{FIGURE}


The goal of that section is to find the parameters that make the distributions of the log-returns generated from market data or from \textit{HSV\_ts()} fit together.
To do so, and according to the differences between \cref{eq:other:hsvstock:riskless,eq:other:hsvvol:riskless} from \cref{eq:other:hsvstock,eq:other:hsvvol}, the parameters to modify are the drift rate $r \to \alpha$, the mean reversion speed $\kappa^{*} \to \kappa$ and the long-run volatility $\theta^* \to \theta$.
Accordingly, the correlation parameter $\rho$ and the volatility of the volatility $\sigma$ stay unchanged from  the risk-neutral to risk-averse world.

I followed the method exhibited at \cref{sec:upstream:logreturn} to get a rough estimate of the drift rate $\alpha$. From the log-returns' first and second moments, I find the value 0.4822917 as the estimation of $\alpha$.

According to \cref{eq:other:kappa:riskless,eq:other:theta:riskless}, in order to  calculate $\kappa$ and $\theta$, the risk premium $\lambda$ has to be estimated.
Practically, to do so, I am using an approximation algorithm developed by \cite{MASS} which is directly available in R through the function \textit{fitdistr} from the R package \textit{MASS}. 
To do the job, that algorithm needs (i) a density function to be fitted along with (ii) a sample of random data as a template.
As defined in \citet{Adrian}, the density of the log-return generated by the HSV model is given by \cref{methodology:density:heston:log}.

\begin{align}
P_t(x) &= \frac{1}{2 \pi} \int_{-\infty}^{\infty} e^{i \phi x + F_t(\phi)} d\phi \label{methodology:density:heston:log} \\
\intertext{where}
F_t(\phi) &= \frac{\kappa \theta}{\sigma^2} \gamma t -
  \frac{2 \kappa \theta}{\sigma ^2} \ln\left(
    \cosh \frac{\omega t}{2} +
    \frac{\omega^2 - \gamma^2 +2 \kappa \gamma}{2 \kappa \omega} \sinh \frac{\omega t}{2}
  \right) \notag \\
\intertext{and}
\omega &= \sqrt{\gamma^2 + \sigma^2 (\phi^2 - i\phi)}, \notag
\gamma = \kappa + i \rho \phi \sigma \notag
\end{align}

By applying the optimization function together with \cref{methodology:density:heston:log} as a density function, data [REF] as template and the variable $\lambda$ as a cursor, the optimization algorithm outputs $\lambda = 4.7883278229$ as best fit arguments for the risk premium.
Therefore, the set of the "risk-averse" parameters is fully described here below in \ref{eq:methodology:arg:heston:riskaverse}.

\begin{align}
  \left \{
  \begin{array}{lcl}
    V(0) &= &0.03798218, \\
    \theta &= &0.02217598, \\
    \sigma &= &0.50378803, \\
    \rho &= &-0.39877827, \\
    \kappa &= &8.789383, \\
    \alpha & = &0.4822917
  \end{array}
  \right \}  
  \label{eq:methodology:arg:heston:riskaverse}
\end{align}

FIGURE shows the distribution of the HSV related log-returns with respect to the distribution of those computed from the market.

[FIGURE]

Consequently, the set \ref{eq:methodology:arg:heston:riskaverse} is the one I will use together with the \textit{HSV\_ts()} function whenever I have to compute time series using the HSV model and within the real world constraints.


















% \SweaveInput{appendix}









\bibliography{bibl}
\bibliographystyle{plainnat}
\end{document}
