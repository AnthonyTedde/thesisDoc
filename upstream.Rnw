%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  CHAPTER:Upstream concepts
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Upstream concepts}
\label{cha:upstream}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: Overview
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section{Overview}
% \label{sec:upstream:overview}

The material covered in the current chapter is meant to be thereafter intensively used, either by being applied in the studied theoretical models or by entering in the construction of the theory-based algorithms.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: Vanilla options
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Vanilla options}
\label{sec:upstream:vanilla}

The so-called vanilla options, in opposition to the more complex - not covered in this master thesis - exotic ones, are specifics kind of derivatives coming along with some good-to-know jargons. 

First and foremost,  as defined in \citet{hull}, an option is a contract between two stakeholders with different interests or at least distinctive motivations, who want to buy or sell a product, which generally is a financial asset called "the underlying." 
Indeed, someone can look for hedge oneself against risk while the other party wants to make a profit on a speculative move.
Likewise other financial contracts, one agrees to buy and the other to sell at a fixed amount of money, namely "the strike price", usually denoted by $k$ with the difference that they would effectively realize the purchase or the sale of the underlying at a future date than the one they enter into the bargain. That date is called "the maturity".


Another key characteristic of options is that they are not symmetric contracts, in the sense that both parties do not have the same rights, depending on their position along with the option's type. 
Two positions can be taken when entering into such a derivative, either long or short. 
Going short broadly means purchase the option whereas going long implies writing, or synonymously, selling the derivative. Beyond the position, the contract can be of call or put type. 

The following sentences encompass a mix of type (call/put) and position (short/long) combination that gives an overview of all the possible scenarios:

\begin{itemize}
\item Someone who is going long into a call gains the right to purchase the underlying at a future date for a fixed price. He has to pay some fees to enter into the contract.
\item Someone who is going short into a call is forced to sell the underlying at a future date for a fixed price. He receives financial compensation to enter into the contract.
\item Someone who is going long into a put gains the right to sell the underlying at a future date for a fixed price. He has to pay some fees to enter into the contract.
\item Someone who is going short into a put is forced to buy the underlying at a future date for a fixed price. He receives financial compensation to enter into the contract.
\end{itemize}

Moreover, vanilla options may be "European" or "American". Latter can be exercised at any time during the whole life of the contract while the European can only be at maturity.

Finally, the payoff provided by all aforementioned European options are summarized throughout \crefrange{eq:upstream:cl}{eq:upstream:ps}, where $C_l$, $C_s$, $P_l$ and $P_s$ respectively stand for the long call, short call, long put and short put payoffs. $S(T)$ being the price of the underlying at maturity.

\begin{align}
C_l &= \left(S(T) - k\right)^+ \label{eq:upstream:cl}\\
C_s &= \left(k - S(T)\right)^- \label{eq:upstream:cs}\\
P_l &= \left(k - S(T)\right)^+ \label{eq:upstream:pl}\\
P_s &= \left(S(T) - k\right)^- \label{eq:upstream:ps}
\end{align}

The derivative considered in this master thesis is mainly the European call option, even though the link with European put could somehow be done without being mandatory to exhibit the issue so raised. Therefore such reference to put should only be done if necessary.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: Brownian Motion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Brownian Motion}
\label{sec:upstream:brownian}
 
All over the present document, the terms "Brownian motion", "Wiener" or "Markov" processes are considered to be equivalent terminology and therefore used as such. However strictly speaking, even though the Brownian motion is in every respect a Wiener process, stricto sensu, the term Markov process is broader. 
Actually, the more remarkable Markov property is to be a process with independent future increments, putting it in line with the weak form of market efficiency (\citet{hull}).
Whilst, on the other hand, even if the Brownian motion, and thus the Wiener process, share this property, they are defined with the idiosyncrasy to have mean zero and a variance rate of one per unit of time (\citet{hull}).

Brownian motion is a centerpiece broadly used in subsequent developments. It is notably applied in many models such as in the geometric Brownian motion (\cref{cha:bsm}),  in the Black-Scholes-Merton (BSM) equation (\cref{cha:bsm}) and in the Merton mixed jump-diffusion (MJD) and Heston stochastic volatility (HSV) model (\cref{cha:OtherModel}).

The Brownian motion is a stochastic process, denoted by $\Bm$ and satisfying $W(0) = 0$, with independent and identically distributed (iid) increments, such as defined by \cref{eq:upstream:increment:dist}

\begin{align}
W(t_{i+1}) - W(t_i) \sim
  iid N \left(0, t_{i+1} - t_i\right) \label{eq:upstream:increment:dist}
\end{align}

That Markov process is qualified as being time and path dependent in its building blocks. Time dependency implies that like many other functions its value evolves over time. 
Whereas path dependency means that the Wiener process is also meant to randomly move between two time-steps.
Practically, at any time $t$ and from its origin, the Brownian motion may take any value as shown by \cref{eq:upstream:brownian:dist}.

\begin{align}
\Bm \sim N(0, t) \label{eq:upstream:brownian:dist}
\end{align}

As described by \citet{shreve}, the construction of such a process could be achieved by following various techniques. Either by computing the differential process (\cref{eq:upstream:brownian:diff,eq:upstream:brownian:cumsum}) for every time-steps and then combining them, by constructing a unique time series in that way; or by resolving the joint moment generating function of the iid random variables' vector ($W(t_i)$ \ldots $W(t_m)$), through \cref{eq:upstream:brownian:joint}.

\begin{align}
  d\Bm &= \phi \left(0, t + \epsilon_i \right) \label{eq:upstream:brownian:diff} \\
  \intertext{
  $\phi$ is a function that generate a random number according to the normal law with parameter $\mu = 0$ and $\sigma^2 = t + \epsilon_i$, with $\epsilon_i$ being any arbitrary small delta time step.
  }
  W\left(t + \epsilon_i\right) &= \Bm + d\Bm \label{eq:upstream:brownian:cumsum}
\end{align}

\begin{align}
  \varphi\left(u_1 \ldots u_m\right) = \exp{\left( \frac{1}{2} \sum_{i = 1}^m \left[ \sum_{j = i}^m u_j \right]^2 \left( t_i - t_{i-1} \right) \right)} \label{eq:upstream:brownian:joint}
\end{align}

\Cref{fig:upstream:brownian} (QA) displays a simulation of one hundred Brownian motions over a time frame of five years. While in turn, \cref{fig:upstream:brownian} (QB) shows the distribution of the possible outcomes of that experiment, after five years. The black outlined curve is the density of the normal distribution, with mean and variance chose such as exposed by \cref{eq:upstream:increment:dist}.

\begin{figure}[H]
\centering
\input{figures/brownianmotion.tex}
\caption{Multiple Brownian motions}
  %
  % BEGIN OF FLOATNOTE
  %
  \begin{changemargin}{0.5cm}{0.5cm}
  \medskip
\footnotesize
\setstretch{1.0}\textbf{Notes.} (QA): Simulation of one hundred Brownian motions by using the function \textit{bmotion} of the R package \textit{randomwalk}, with a timeframe of five years and a discrete time-step of one over one hundred.
(QB): The blue filled curve is the density computed on the simulation (QA). The distribution concerns all the final values $W(T = 5)$. The Black bell curve represents the normal density with mean zero and a standard deviation of square root of five.   
\end{changemargin}
  %
  % END OF FLOATNOTE
  %
\label{fig:upstream:brownian}
\end{figure}

Lastly, \citet{shreve} demonstrates that a Brownian motion has no tendency to rise or fall as time passes thanks to its martingale property. Therefore, because its initial value is zero, a Wiener process only brings noise by being incorporated into other stochastic series.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SUBSECTION: Correlated Brownian Motion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Correlated Brownian motions}
\label{sub:upstream:brownian:correlated}

Correlated Brownian motions are Wiener processes that related together according to the factor $\rho$ \ref{eq:upstream:brownian:corr}.
Following \citet{shreve}, these processes happens to be modeled by \cref{eq:upstream:brownian:corr:1,eq:upstream:brownian:corr:2}.

\begin{align}
  dB_1(t) dB_2(t) &= \rho(t) dt \label{eq:upstream:brownian:corr} \\
  \intertext{Where $dB_1(t)$ and $dB_2(t)$ are Wiener process }
  B_1(t) &= W_1(t) \label{eq:upstream:brownian:corr:1} \\
  B_2(t) &= \int_0^t \rho(s) dW_1(s) + \int_0^t \sqrt{1 - \rho^2(s)} dW_2(s) \label{eq:upstream:brownian:corr:2}
\end{align}

whenever $\rho$ is considered as constant over time, however, the simple form given by  \cref{eq:upstream:brownian:corr:deterministic:2} is enough to construct such processes.

\begin{align}
B_2(t) &= \rho W_1(s) + \sqrt{1 - \rho^2} W_2(s) \label{eq:upstream:brownian:corr:deterministic:2}
\end{align}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: Cox-Ingersoll-Ross
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Ito's lemma}
\label{sec:upstream:ito}

Based on Taylor approximation theorem, Ito formulae are meant to provide the differential form of such a function $f \circ g$ where the function $f$ can be differentiated with respect to its independent variable whilst g cannot.

\begin{align}
  f(T, W(T)) = f(0, W(0))
               + \int_0^T \frac{\partial f(t, W(t))}{\partial t} dt
               + \int_0^T \frac{\partial f(t, W(t))}{\partial W(t)} dW(t)\notag\\
    \mspace{150mu} + \frac{1}{2} \int_0^T \frac{\partial^2 f(t, W(t))}{\partial W(t)^2} dt \label{eq:upstream:itodiff:brownian}
\end{align}

While \cref{eq:upstream:itodiff:brownian} shows the formula for Brownian motion, the \cref{eq:upstream:itodiff:itopro} represents the form used to differentiate the more complex Ito process (\ref{eq:upstream:itopro}).

\begin{align}
  X(T) &= X(0)
         + \int_0^T \Delta(u) dW(u)
         + \int_0^T \Theta(u) du \label{eq:upstream:itopro} \\
  \intertext{
  Where $\Delta(u)$ and $\Theta(u)$ are stochastic process, adapted to a filtration f(t)
  }
  f(T, X(T)) &= f(0, X(0))
               + \int_0^T \frac{\partial f(t, X(t))}{\partial t} dt
               + \int_0^T \frac{\partial f(t, X(t))}{\partial X(t)} \Delta(t) dW(t)\notag\\
    &\mspace{50mu} + \int_0^T \frac{\partial f(t, X(t))}{\partial X(t)} \Theta(t) dt
    + \frac{1}{2} \int_0^T \frac{\partial^2 f(t, X(t))}{\partial W(t)^2} \Delta^2(t)dt \label{eq:upstream:itodiff:itopro}
\end{align}

Ito formulae are thereafter applied to derive such a process like the geometric Brownian motion or the Black-Scholes-Merton partial differential equation. 







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: Cox-Ingersoll-Ross
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Cox-Ingersoll-Ross}
\label{sec:CoxIngersollRoss}

The Cox-Ingersoll-Ross (CIR) stochastic model $R(t)$, defined by the differential \cref{eq:upstream:cir}), can be used to simulate interest rates' evolution over time thanks to some of its intrinsic characteristics, namely the mean-reversion and its property to only take positive values (\citet{shreve}).

\begin{align}
dR(t) &= (\alpha - \beta R(t)) dt + \sigma \sqrt{R(t)} dW(t)
\label{eq:upstream:cir}
\end{align}

According to \citet{shreve}, a  mean-reverting stochastic process tends to navigate, such a pointy sinusoidal motion, around its mean.
The CIR inherits this behaviour from the construction of its differential's drift part, i.e. $(\alpha - \beta R(t))dt$.
Indeed when $R(t) = \sfrac{\alpha}{\beta}$, then the drift term $dt = 0$ with the consequence of status quo.
In addition, whether $R(t) > \sfrac{\alpha}{\beta}$ or $R(t) < \sfrac{\alpha}{\beta}$, the next value of $R(t + \epsilon) = R(t) + dR(t)$ is pushed back toward $\sfrac{\alpha}{\beta}$.
Actually, as showing by \cref{eq:upstream:cir:exp}, the long-run expected value for the process $R(t)$ is $\sfrac{\alpha}{\beta}$.

\begin{align}
\lim_{t \to \infty}  \mathop{\mathbb{E}} R(t) = \frac{\alpha}{\beta} \label{eq:upstream:cir:exp}
\end{align}

On the other hand, depending on \citet{shreve}, the non-negativity property is explained by the fact that if $R(t) \to 0$ then $dR(t) \simeq \alpha dt > 0$ making $R(t+\epsilon)$ bounced off the x axis, running it away from negative realm.

Ultimately, the CIR mean-reverting \cref{eq:upstream:cir} is used by \citet{heston1993} in its pricing model to construct stochastic interest rates.
Heston's model is covered in \cref{sec:other:heston}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: Moments
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Skewness and Kurtosis}
\label{sec:Moments}



The skewness and kurtosis of a random variable's distribution, whose respectively are the third and fourth moment, characterize either the asymmetry, for the first, or the degree of flatness, for the second.

The theoretical moments are defined by \cref{eq:upstream:moment:theoretical} while those empirical can be estimated using \cref{eq:upstream:moment:empirical}, with the parameter $r = 3$ to compute the skewness or $r= 4$ for the kurtosis.

\begin{align}
\gamma_r = \mathop{{}\mathbb{E}} \left[ \left( \frac{X - \mu}{\sigma} \right) ^r \right] \label{eq:upstream:moment:theoretical}
\intertext{where $X$ is any random variable}
m_r = \frac{1}{n} \sum_{i = 1}^n (x_i - \overline{\rm x}) ^r \label{eq:upstream:moment:empirical}
\end{align}
with $\{x_i\}_{i \in n}$ being a set of outcomes belonging to the sample set.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SUBSECTION: Estimation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Estimation}
\label{sub:Estimation}

As demonstrated in \citet{sk}, sampled skewness and kurtosis formulae can be computed in some different fashions
All of these methods bring their precisions to the calculation of those moments. 
The precision of the method mostly depends on the size of the sample along with the skewed of the theoretical distribution to be estimated.

The method having to be chosen to estimate the skewness and kurtosis needs a prudent selection especially for a small sample size. 
Actually, in order to minimize the mean-squared error and the associated variance, the \cref{eq:upstream:skewness:normal,eq:upstream:kurtosis:normal} are used as a reliable unbiased estimator for a sample with normal shaped theoretical distribution.

\begin{align}
  b_{skewness} &= \frac{m_3}{S^3} \label{eq:upstream:skewness:normal} \\ 
  b_{kurtosis} &= \frac{m_4}{S^4} \label{eq:upstream:kurtosis:normal} \\
  \intertext{
  where
  }
  S^2 &= \frac{1}{n - 1} \sum_{i = 1}^n \left( x_i - \overline{\rm x} \right)^2 \notag \\
  \intertext{
  Conversely, \cref{eq:upstream:skewness:skewed,eq:upstream:kurtosis:skewed} are the ones providing a better-unbiased estimation for more skewed distributions, such as for log-normal random variable's samples.
  }
  G_{skewness} &= \frac{k_3}{\sqrt{k_2^3}} \label{eq:upstream:skewness:skewed} \\ 
  G_{kurtosis} &= \frac{k_4}{k_2^2} \label{eq:upstream:kurtosis:skewed}  \\
  \intertext{
  where
  }
  K_2 &= \frac{n}{n-1} m_2 \notag \\
  K_3 &= \frac{n}{(n-1)(n-2)} m_3 \notag \\
  K_4 &= \frac{n}{\prod_{i = 1}^3 n - i} \Big[ (n+1)m_4 - 3(n-1) m_2 ^2 \Big] \notag
\end{align}

Accordingly, the algorithm to apply in order to estimate the skewness and kurtosis from samples should be chosen with respect to the theoretical underpinned distribution.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: Log-return and compounded interest rate
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Log-return and compounded interest rate}
\label{sec:upstream:logreturn}

Following \citet{hull}, the concept of log-returns and continuously compounded interest rates are closely related together as attested by \crefrange{eq:upstream:stock:valued}{eq:upstream:logreturn}.

\begin{align}
&S(0) e^{R_c t} = \St \label{eq:upstream:stock:valued} \\
\Longleftrightarrow  &\ln{S(0)} + R_c t = \ln{\St} \\
\Longleftrightarrow  &\ln{\frac{\St}{S(0)}} = R_c t \label{eq:upstream:logreturn}
\end{align}
Where $R_c$ is the interest rate with continuous compounding, $t$ denotes the time period across which the interests are compounded ($t$ is yearly-based) while the left-hand side of \cref{eq:upstream:logreturn} stands for the natural logarithm of the stock return occurring during the period $t$, the so-called log-return.

As showed in \citet{hull}, the transformation of an equivalent rate $R_m$ with a frequency of compounding $m$ per year into one continuous could be perform thanks to \cref{eq:upstream:equivtocontinuous}

\begin{align}
R_c = m \ln \left( 1 + \frac{R_m}{m} \right) \label{eq:upstream:equivtocontinuous}
\end{align}

For what matters in that master thesis, the focus is set to the sample's log-returns which are used to estimate the volatility term appearing, inter alia, in \cref{eq:underlying:geometric:closed} in order to simulate geometric Brownian motion.

In accordance with \citet{hull}, if $S_i$ and $n$ respectively denote the stock price at the end of interval $i$ and the total number of observations then the log-returns of the ordered sample set $\{S_i\}_{i \in n}$ is given by \cref{eq:upstream:logreturn:sample}.

\begin{align}
  u_i &= \ln \frac{S_i}{S_{i-1}} \label{eq:upstream:logreturn:sample} \\
  \intertext{
  Whilst the estimation of the standard deviation of all the $u_i$ is defined as such in \cref{eq:upstream:logreturn:sd}
  }
  s &= \sqrt{\frac{1}{n - 1} \sum_{i = 1}^n \left(u_i - \bar{u} \right) ^2} \label{eq:upstream:logreturn:sd}
\end{align}

Consequently, if the distribution of the log-returns of a stochastic process is normal and is given by \cref{eq:upstream:log:distrib:normal}, the parameters $\alpha$ and $\sigma$ can be assessed by respectively using \cref{eq:upstream:mean:estimator,eq:upstream:volatility:estimator}.
This method will be used notably used in \cref{cha:Methodology} to find the calibrated value of some parameters.

\begin{align}
  N \sim \left( \left( \alpha - \frac{\sigma^ 2}{2} \right) t, \sigma^2 t \right) \label{eq:upstream:log:distrib:normal}
\end{align}

\begin{align}
  \hat{\alpha} &= \frac{\bar{x}}{t} + \frac{\hat{\sigma}^2}{2} \label{eq:upstream:mean:estimator}\\
  \hat{\sigma} &= \frac{s}{\sqrt{t}} \label{eq:upstream:volatility:estimator}
\end{align}














